{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7647edb6-04eb-40fb-b083-7caa5d864c88",
   "metadata": {},
   "source": [
    "#### BrisT1D Blood Glucose Prediction Competition\r\n",
    "Using historical blood glucose readings, insulin dosage, carbohydrate intake, and smartwatch activity data to predict future blood glucose\n",
    "\n",
    "Kaggle - https://www.kaggle.com/competitions/brist1d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e2a4ba-8510-43fc-b204-f5fd43f64c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680df4ff-74d5-4d9c-9d7b-b455736256c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_data = TabularDataset('train.csv')\n",
    "test_data = TabularDataset('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba9cb9c-206b-460e-b43c-7bd9b71a0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>p_num</th>\n",
       "      <th>time</th>\n",
       "      <th>bg-5:55</th>\n",
       "      <th>bg-5:50</th>\n",
       "      <th>bg-5:45</th>\n",
       "      <th>bg-5:40</th>\n",
       "      <th>bg-5:35</th>\n",
       "      <th>bg-5:30</th>\n",
       "      <th>bg-5:25</th>\n",
       "      <th>...</th>\n",
       "      <th>activity-0:40</th>\n",
       "      <th>activity-0:35</th>\n",
       "      <th>activity-0:30</th>\n",
       "      <th>activity-0:25</th>\n",
       "      <th>activity-0:20</th>\n",
       "      <th>activity-0:15</th>\n",
       "      <th>activity-0:10</th>\n",
       "      <th>activity-0:05</th>\n",
       "      <th>activity-0:00</th>\n",
       "      <th>bg+1:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p01_0</td>\n",
       "      <td>p01</td>\n",
       "      <td>06:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p01_1</td>\n",
       "      <td>p01</td>\n",
       "      <td>06:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p01_2</td>\n",
       "      <td>p01</td>\n",
       "      <td>06:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p01_3</td>\n",
       "      <td>p01</td>\n",
       "      <td>06:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p01_4</td>\n",
       "      <td>p01</td>\n",
       "      <td>07:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id p_num      time  bg-5:55  bg-5:50  bg-5:45  bg-5:40  bg-5:35  \\\n",
       "0  p01_0   p01  06:10:00      NaN      NaN      9.6      NaN      NaN   \n",
       "1  p01_1   p01  06:25:00      NaN      NaN      9.7      NaN      NaN   \n",
       "2  p01_2   p01  06:40:00      NaN      NaN      9.2      NaN      NaN   \n",
       "3  p01_3   p01  06:55:00      NaN      NaN      8.7      NaN      NaN   \n",
       "4  p01_4   p01  07:10:00      NaN      NaN      8.4      NaN      NaN   \n",
       "\n",
       "   bg-5:30  bg-5:25  ...  activity-0:40  activity-0:35  activity-0:30  \\\n",
       "0      9.7      NaN  ...            NaN            NaN            NaN   \n",
       "1      9.2      NaN  ...            NaN            NaN            NaN   \n",
       "2      8.7      NaN  ...            NaN            NaN            NaN   \n",
       "3      8.4      NaN  ...            NaN            NaN            NaN   \n",
       "4      8.1      NaN  ...            NaN            NaN            NaN   \n",
       "\n",
       "   activity-0:25  activity-0:20  activity-0:15  activity-0:10  activity-0:05  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   activity-0:00  bg+1:00  \n",
       "0            NaN     13.4  \n",
       "1            NaN     12.8  \n",
       "2            NaN     15.5  \n",
       "3            NaN     14.8  \n",
       "4            NaN     12.7  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb65502-3c87-494b-914b-885241e6dd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177024, 508)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d6ee40-9401-4d01-8b92-b6583224016e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3644, 507)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1a8856-53f2-4693-8020-8dd16cec2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to optimize memory usage by downcasting\n",
    "def optimize_memory(df):\n",
    "    for col in df.select_dtypes(include=['float']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    for col in df.select_dtypes(include=['int']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dba197e-32ad-4b77-a981-e8fd33dddf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = optimize_memory(train_data)\n",
    "# test_data = optimize_memory(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd8ba55-f4a4-4780-848f-41f35ba2b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target column for prediction\n",
    "target = 'bg+1:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8d884-9c8f-45fb-9a4f-595a0c0cccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241114_175825\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       22.22 GB / 31.82 GB (69.8%)\n",
      "Disk Space Avail:   633.57 GB / 953.00 GB (66.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 9900s of the 39600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-14 21:58:27,945\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels\\ag-20241114_175825\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Beginning AutoGluon training ... Time limit = 9895s\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m AutoGluon will save models to \"AutogluonModels\\ag-20241114_175825\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Train Data Rows:    157354\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Train Data Columns: 507\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Label Column:       bg+1:00\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tAvailable Memory:                    19860.87 MB\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tTrain Data (Original)  Memory Usage: 897.99 MB (4.5% of available memory)\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tUnused Original Features (Count: 1): ['id']\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('object', []) : 1 | ['id']\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('float', [])                      : 432 | ['bg-5:55', 'bg-5:50', 'bg-5:45', 'bg-5:40', 'bg-5:35', ...]\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('object', [])                     :  73 | ['p_num', 'activity-5:55', 'activity-5:50', 'activity-5:45', 'activity-5:40', ...]\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('object', ['datetime_as_object']) :   1 | ['time']\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('category', [])             :  73 | ['p_num', 'activity-5:55', 'activity-5:50', 'activity-5:45', 'activity-5:40', ...]\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('float', [])                : 432 | ['bg-5:55', 'bg-5:50', 'bg-5:45', 'bg-5:40', 'bg-5:35', ...]\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t\t('int', ['datetime_as_int']) :   1 | ['time']\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t15.5s = Fit runtime\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t506 features in original data used to generate 506 features in processed data.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tTrain Data (Processed) Memory Usage: 530.82 MB (2.7% of available memory)\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Data preprocessing and feature engineering runtime = 17.06s ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Fitting 106 L1 models ...\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6583.5s of the 9877.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.56% memory usage per fold, 70.25%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18048)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=17.56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=20692)\u001b[0m [1000]\tvalid_set's rmse: 1.70294\n",
      "\u001b[36m(_ray_fit pid=20692)\u001b[0m [2000]\tvalid_set's rmse: 1.6239\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19292)\u001b[0m [3000]\tvalid_set's rmse: 1.57209\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AutoGluon TabularPredictor for regression\n",
    "predictor = TabularPredictor(\n",
    "    label=target,                   # Target column for blood glucose level prediction\n",
    "    eval_metric='rmse',             # Evaluation metric as required by the competition\n",
    "    problem_type='regression'       # Set to regression for continuous value prediction\n",
    ").fit(\n",
    "    train_data,\n",
    "    presets='best_quality',         # Best quality preset for more accurate predictions\n",
    "    time_limit=3600 * 11,           # Training time limit (11 hours, adjust as needed)\n",
    "    verbosity=2,                    # Detailed logs for tracking\n",
    "    excluded_model_types=['KNN'],   # Exclude KNN for efficiency on large datasets\n",
    "    ag_args_fit={'num_cpus': 10, 'memory_ratio': 0.8}  # Optimized CPU, GPU, and memory usage\n",
    ")\n",
    "\n",
    "# Summarize results after training\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63437c-a6a9-4ca2-b991-def65a8d089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data without the target column for prediction\n",
    "test_data_no_target = test_data.drop(columns=[target], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b34e5-f391-4689-a74d-14fc21abac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = predictor.predict(test_data_no_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d34a3-6738-47dd-ba4f-be7b81ec4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({'id': test_data['id'], target: predictions})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as submission.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5c61e-380e-41a8-8b21-dd950896887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7640d-d32e-4207-b6cb-3e060a5c5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the leaderboard to see the performance of the models\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "\n",
    "# Print the leaderboard for reference\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fae54b-25d8-4be2-a0f4-479591cce006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 models based on the leaderboard\n",
    "top_10_models = leaderboard['model'].head(10).tolist()\n",
    "top_10_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d386c1-5a41-4359-a1a5-487f60e5acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the top 10 models and print their hyperparameters\n",
    "for model in top_10_models:\n",
    "    hyperparameters = predictor.info()['model_info'][model]['hyperparameters']\n",
    "    print(f\"Model: {model}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(hyperparameters)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21456588-99d9-4d02-80f4-f7b6533ad50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details of the best model\n",
    "best_model = predictor.get_model_best()\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "# Get model hyperparameters and other info\n",
    "best_model_info = predictor.info()\n",
    "print(best_model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148decc-275f-450d-a99b-37a7639df1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = predictor.feature_importance(train_data)\n",
    "print(\"Feature Importance:\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0bce4-397a-4540-a214-d61ad7461026",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b841d-f3f4-4df6-9c79-2b24b766d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207192ce-b9dd-46ee-aced-0945a50b0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 models based on the leaderboard\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "top_10_models = leaderboard['model'].head(10).tolist()\n",
    "\n",
    "# Prepare the test data without the target column for prediction\n",
    "test_data_no_target = test_data.drop(columns=[target], errors='ignore')\n",
    "\n",
    "# Make predictions with each top model and save to individual submission files\n",
    "for model in top_10_models:\n",
    "    predictions = predictor.predict(test_data_no_target, model=model)\n",
    "    submission = pd.DataFrame({'id': test_data['id'], target: predictions})\n",
    "    submission_file = f\"submission_{model}.csv\"\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    print(f\"Submission file saved for model {model} as {submission_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bdb1d-feb4-4fa4-9463-7da1167122f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
