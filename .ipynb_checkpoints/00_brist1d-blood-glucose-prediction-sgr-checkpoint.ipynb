{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82611,"databundleVersionId":9553358,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:18.341295Z","iopub.execute_input":"2024-11-16T16:09:18.341876Z","iopub.status.idle":"2024-11-16T16:09:19.474349Z","shell.execute_reply.started":"2024-11-16T16:09:18.341819Z","shell.execute_reply":"2024-11-16T16:09:19.473450Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/brist1d/sample_submission.csv\n/kaggle/input/brist1d/activities.txt\n/kaggle/input/brist1d/train.csv\n/kaggle/input/brist1d/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport optuna\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import early_stopping\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:19.475974Z","iopub.execute_input":"2024-11-16T16:09:19.476365Z","iopub.status.idle":"2024-11-16T16:09:24.974152Z","shell.execute_reply.started":"2024-11-16T16:09:19.476331Z","shell.execute_reply":"2024-11-16T16:09:24.973113Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/brist1d/train.csv')\ntest=pd.read_csv('/kaggle/input/brist1d/test.csv')\ntrain.shape,test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:24.975291Z","iopub.execute_input":"2024-11-16T16:09:24.975909Z","iopub.status.idle":"2024-11-16T16:09:38.604715Z","shell.execute_reply.started":"2024-11-16T16:09:24.975869Z","shell.execute_reply":"2024-11-16T16:09:38.603743Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((177024, 508), (3644, 507))"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:38.607370Z","iopub.execute_input":"2024-11-16T16:09:38.607731Z","iopub.status.idle":"2024-11-16T16:09:38.646243Z","shell.execute_reply.started":"2024-11-16T16:09:38.607696Z","shell.execute_reply":"2024-11-16T16:09:38.645360Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      id p_num      time  bg-5:55  bg-5:50  bg-5:45  bg-5:40  bg-5:35  \\\n0  p01_0   p01  06:10:00      NaN      NaN      9.6      NaN      NaN   \n1  p01_1   p01  06:25:00      NaN      NaN      9.7      NaN      NaN   \n2  p01_2   p01  06:40:00      NaN      NaN      9.2      NaN      NaN   \n3  p01_3   p01  06:55:00      NaN      NaN      8.7      NaN      NaN   \n4  p01_4   p01  07:10:00      NaN      NaN      8.4      NaN      NaN   \n5  p01_5   p01  07:25:00      NaN      NaN      8.1      NaN      NaN   \n6  p01_6   p01  07:40:00      NaN      NaN      8.3      NaN      NaN   \n7  p01_7   p01  07:55:00      NaN      NaN      9.6      NaN      NaN   \n8  p01_8   p01  08:10:00      NaN      NaN     11.1      NaN      NaN   \n9  p01_9   p01  08:25:00      NaN      NaN     11.8      NaN      NaN   \n\n   bg-5:30  bg-5:25  ...  activity-0:40  activity-0:35  activity-0:30  \\\n0      9.7      NaN  ...            NaN            NaN            NaN   \n1      9.2      NaN  ...            NaN            NaN            NaN   \n2      8.7      NaN  ...            NaN            NaN            NaN   \n3      8.4      NaN  ...            NaN            NaN            NaN   \n4      8.1      NaN  ...            NaN            NaN            NaN   \n5      8.3      NaN  ...            NaN            NaN            NaN   \n6      9.6      NaN  ...            NaN            NaN            NaN   \n7     11.1      NaN  ...            NaN            NaN            NaN   \n8     11.8      NaN  ...            NaN            NaN            NaN   \n9     12.8      NaN  ...            NaN            NaN            NaN   \n\n   activity-0:25  activity-0:20  activity-0:15  activity-0:10  activity-0:05  \\\n0            NaN            NaN            NaN            NaN            NaN   \n1            NaN            NaN            NaN            NaN            NaN   \n2            NaN            NaN            NaN            NaN            NaN   \n3            NaN            NaN            NaN            NaN            NaN   \n4            NaN            NaN            NaN            NaN            NaN   \n5            NaN            NaN            NaN            NaN            NaN   \n6            NaN            NaN            NaN            NaN            NaN   \n7            NaN            NaN            NaN            NaN            NaN   \n8            NaN            NaN            NaN            NaN            NaN   \n9            NaN            NaN            NaN            NaN            NaN   \n\n   activity-0:00  bg+1:00  \n0            NaN     13.4  \n1            NaN     12.8  \n2            NaN     15.5  \n3            NaN     14.8  \n4            NaN     12.7  \n5            NaN     11.4  \n6            NaN     11.9  \n7            NaN     15.1  \n8            NaN     17.1  \n9            NaN     17.9  \n\n[10 rows x 508 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>p_num</th>\n      <th>time</th>\n      <th>bg-5:55</th>\n      <th>bg-5:50</th>\n      <th>bg-5:45</th>\n      <th>bg-5:40</th>\n      <th>bg-5:35</th>\n      <th>bg-5:30</th>\n      <th>bg-5:25</th>\n      <th>...</th>\n      <th>activity-0:40</th>\n      <th>activity-0:35</th>\n      <th>activity-0:30</th>\n      <th>activity-0:25</th>\n      <th>activity-0:20</th>\n      <th>activity-0:15</th>\n      <th>activity-0:10</th>\n      <th>activity-0:05</th>\n      <th>activity-0:00</th>\n      <th>bg+1:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p01_0</td>\n      <td>p01</td>\n      <td>06:10:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.7</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p01_1</td>\n      <td>p01</td>\n      <td>06:25:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.2</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>p01_2</td>\n      <td>p01</td>\n      <td>06:40:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.7</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p01_3</td>\n      <td>p01</td>\n      <td>06:55:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.4</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>p01_4</td>\n      <td>p01</td>\n      <td>07:10:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>p01_5</td>\n      <td>p01</td>\n      <td>07:25:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>p01_6</td>\n      <td>p01</td>\n      <td>07:40:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.6</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>p01_7</td>\n      <td>p01</td>\n      <td>07:55:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>p01_8</td>\n      <td>p01</td>\n      <td>08:10:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.8</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>p01_9</td>\n      <td>p01</td>\n      <td>08:25:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.8</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 508 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:38.647676Z","iopub.execute_input":"2024-11-16T16:09:38.647974Z","iopub.status.idle":"2024-11-16T16:09:38.654466Z","shell.execute_reply.started":"2024-11-16T16:09:38.647942Z","shell.execute_reply":"2024-11-16T16:09:38.653470Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'p_num', 'time', 'bg-5:55', 'bg-5:50', 'bg-5:45', 'bg-5:40',\n       'bg-5:35', 'bg-5:30', 'bg-5:25',\n       ...\n       'activity-0:40', 'activity-0:35', 'activity-0:30', 'activity-0:25',\n       'activity-0:20', 'activity-0:15', 'activity-0:10', 'activity-0:05',\n       'activity-0:00', 'bg+1:00'],\n      dtype='object', length=508)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:38.655833Z","iopub.execute_input":"2024-11-16T16:09:38.656523Z","iopub.status.idle":"2024-11-16T16:09:38.702565Z","shell.execute_reply.started":"2024-11-16T16:09:38.656477Z","shell.execute_reply":"2024-11-16T16:09:38.701583Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 177024 entries, 0 to 177023\nColumns: 508 entries, id to bg+1:00\ndtypes: float64(433), object(75)\nmemory usage: 686.1+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:38.703835Z","iopub.execute_input":"2024-11-16T16:09:38.704106Z","iopub.status.idle":"2024-11-16T16:09:42.104924Z","shell.execute_reply.started":"2024-11-16T16:09:38.704076Z","shell.execute_reply":"2024-11-16T16:09:42.104030Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"             bg-5:55        bg-5:50        bg-5:45        bg-5:40  \\\ncount  149770.000000  158533.000000  163364.000000  149766.000000   \nmean        8.211018       8.230449       8.253291       8.210988   \nstd         2.852188       2.913438       2.945594       2.852090   \nmin         2.200000       2.200000       2.200000       2.200000   \n25%         6.100000       6.100000       6.100000       6.100000   \n50%         7.600000       7.600000       7.700000       7.600000   \n75%         9.800000       9.800000       9.800000       9.800000   \nmax        22.200000      25.100000      27.800000      22.200000   \n\n             bg-5:35        bg-5:30        bg-5:25        bg-5:20  \\\ncount  158254.000000  163770.000000  149763.000000  157973.000000   \nmean        8.229649       8.254083       8.211049       8.228888   \nstd         2.911313       2.947651       2.852212       2.909304   \nmin         2.200000       2.200000       2.200000       2.200000   \n25%         6.100000       6.100000       6.100000       6.100000   \n50%         7.600000       7.700000       7.600000       7.600000   \n75%         9.800000       9.800000       9.800000       9.800000   \nmax        25.100000      27.800000      22.200000      25.100000   \n\n             bg-5:15        bg-5:10  ...      cals-0:40      cals-0:35  \\\ncount  164174.000000  149771.000000  ...  141694.000000  141706.000000   \nmean        8.254602       8.211000  ...       9.364063       9.364096   \nstd         2.949689       2.852315  ...       8.012264       8.012681   \nmin         2.200000       2.200000  ...       0.030000       0.030000   \n25%         6.100000       6.100000  ...       5.600000       5.600000   \n50%         7.700000       7.600000  ...       6.180000       6.180000   \n75%         9.800000       9.800000  ...       9.060000       9.060000   \nmax        27.800000      22.200000  ...     116.100000     116.100000   \n\n           cals-0:30      cals-0:25      cals-0:20      cals-0:15  \\\ncount  141713.000000  141722.000000  141732.000000  141741.000000   \nmean        9.362525       9.366591       9.368108       9.366998   \nstd         8.017508       8.018465       8.018349       8.023788   \nmin         0.030000       0.030000       0.030000       0.030000   \n25%         5.600000       5.600000       5.600000       5.600000   \n50%         6.170000       6.180000       6.180000       6.180000   \n75%         9.050000       9.060000       9.060000       9.060000   \nmax       116.100000     116.100000     116.100000     116.100000   \n\n           cals-0:10      cals-0:05      cals-0:00        bg+1:00  \ncount  141751.000000  141761.000000  141767.000000  177024.000000  \nmean        9.370010       9.372536       9.368960       8.277045  \nstd         8.021999       8.023280       8.023327       2.996398  \nmin         0.030000       0.030000       0.030000       2.200000  \n25%         5.600000       5.600000       5.600000       6.100000  \n50%         6.180000       6.180000       6.180000       7.700000  \n75%         9.060000       9.070000       9.060000       9.900000  \nmax       116.100000     116.100000     116.100000      27.800000  \n\n[8 rows x 433 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bg-5:55</th>\n      <th>bg-5:50</th>\n      <th>bg-5:45</th>\n      <th>bg-5:40</th>\n      <th>bg-5:35</th>\n      <th>bg-5:30</th>\n      <th>bg-5:25</th>\n      <th>bg-5:20</th>\n      <th>bg-5:15</th>\n      <th>bg-5:10</th>\n      <th>...</th>\n      <th>cals-0:40</th>\n      <th>cals-0:35</th>\n      <th>cals-0:30</th>\n      <th>cals-0:25</th>\n      <th>cals-0:20</th>\n      <th>cals-0:15</th>\n      <th>cals-0:10</th>\n      <th>cals-0:05</th>\n      <th>cals-0:00</th>\n      <th>bg+1:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>149770.000000</td>\n      <td>158533.000000</td>\n      <td>163364.000000</td>\n      <td>149766.000000</td>\n      <td>158254.000000</td>\n      <td>163770.000000</td>\n      <td>149763.000000</td>\n      <td>157973.000000</td>\n      <td>164174.000000</td>\n      <td>149771.000000</td>\n      <td>...</td>\n      <td>141694.000000</td>\n      <td>141706.000000</td>\n      <td>141713.000000</td>\n      <td>141722.000000</td>\n      <td>141732.000000</td>\n      <td>141741.000000</td>\n      <td>141751.000000</td>\n      <td>141761.000000</td>\n      <td>141767.000000</td>\n      <td>177024.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.211018</td>\n      <td>8.230449</td>\n      <td>8.253291</td>\n      <td>8.210988</td>\n      <td>8.229649</td>\n      <td>8.254083</td>\n      <td>8.211049</td>\n      <td>8.228888</td>\n      <td>8.254602</td>\n      <td>8.211000</td>\n      <td>...</td>\n      <td>9.364063</td>\n      <td>9.364096</td>\n      <td>9.362525</td>\n      <td>9.366591</td>\n      <td>9.368108</td>\n      <td>9.366998</td>\n      <td>9.370010</td>\n      <td>9.372536</td>\n      <td>9.368960</td>\n      <td>8.277045</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.852188</td>\n      <td>2.913438</td>\n      <td>2.945594</td>\n      <td>2.852090</td>\n      <td>2.911313</td>\n      <td>2.947651</td>\n      <td>2.852212</td>\n      <td>2.909304</td>\n      <td>2.949689</td>\n      <td>2.852315</td>\n      <td>...</td>\n      <td>8.012264</td>\n      <td>8.012681</td>\n      <td>8.017508</td>\n      <td>8.018465</td>\n      <td>8.018349</td>\n      <td>8.023788</td>\n      <td>8.021999</td>\n      <td>8.023280</td>\n      <td>8.023327</td>\n      <td>2.996398</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>2.200000</td>\n      <td>...</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>0.030000</td>\n      <td>2.200000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>6.100000</td>\n      <td>...</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>5.600000</td>\n      <td>6.100000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7.600000</td>\n      <td>7.600000</td>\n      <td>7.700000</td>\n      <td>7.600000</td>\n      <td>7.600000</td>\n      <td>7.700000</td>\n      <td>7.600000</td>\n      <td>7.600000</td>\n      <td>7.700000</td>\n      <td>7.600000</td>\n      <td>...</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>6.170000</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>6.180000</td>\n      <td>7.700000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>9.800000</td>\n      <td>...</td>\n      <td>9.060000</td>\n      <td>9.060000</td>\n      <td>9.050000</td>\n      <td>9.060000</td>\n      <td>9.060000</td>\n      <td>9.060000</td>\n      <td>9.060000</td>\n      <td>9.070000</td>\n      <td>9.060000</td>\n      <td>9.900000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>22.200000</td>\n      <td>25.100000</td>\n      <td>27.800000</td>\n      <td>22.200000</td>\n      <td>25.100000</td>\n      <td>27.800000</td>\n      <td>22.200000</td>\n      <td>25.100000</td>\n      <td>27.800000</td>\n      <td>22.200000</td>\n      <td>...</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>116.100000</td>\n      <td>27.800000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 433 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:42.106415Z","iopub.execute_input":"2024-11-16T16:09:42.107074Z","iopub.status.idle":"2024-11-16T16:09:42.712224Z","shell.execute_reply.started":"2024-11-16T16:09:42.107025Z","shell.execute_reply":"2024-11-16T16:09:42.711249Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"id                    0\np_num                 0\ntime                  0\nbg-5:55           27254\nbg-5:50           18491\n                  ...  \nactivity-0:15    174293\nactivity-0:10    174287\nactivity-0:05    174271\nactivity-0:00    174287\nbg+1:00               0\nLength: 508, dtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Create a mask of columns to drop in the training set\ntrain_missing = train.isnull().mean()*100\n\n# Identify columns with more than 20% missing data in train\ncolumns_to_drop = train_missing[train_missing > 25].index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:42.713562Z","iopub.execute_input":"2024-11-16T16:09:42.713901Z","iopub.status.idle":"2024-11-16T16:09:43.316214Z","shell.execute_reply.started":"2024-11-16T16:09:42.713868Z","shell.execute_reply":"2024-11-16T16:09:43.315107Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"columns_to_drop.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.319948Z","iopub.execute_input":"2024-11-16T16:09:43.320248Z","iopub.status.idle":"2024-11-16T16:09:43.326367Z","shell.execute_reply.started":"2024-11-16T16:09:43.320216Z","shell.execute_reply":"2024-11-16T16:09:43.325195Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(288,)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Drop the identified columns from both df_train and df_test\ntrain_cleaned = train.drop(columns=columns_to_drop)\ntest_cleaned = test.drop(columns=columns_to_drop)\n\n\ntrain_cleaned.shape,test_cleaned.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.327682Z","iopub.execute_input":"2024-11-16T16:09:43.327977Z","iopub.status.idle":"2024-11-16T16:09:43.434934Z","shell.execute_reply.started":"2024-11-16T16:09:43.327946Z","shell.execute_reply":"2024-11-16T16:09:43.434023Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"((177024, 220), (3644, 219))"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Check the result\nprint(f\"Columns dropped: {columns_to_drop}\")\nprint(\"Updated df_train:\",train_cleaned.shape)\nprint(\"Updated df_test:\",test_cleaned.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.436186Z","iopub.execute_input":"2024-11-16T16:09:43.436524Z","iopub.status.idle":"2024-11-16T16:09:43.442159Z","shell.execute_reply.started":"2024-11-16T16:09:43.436487Z","shell.execute_reply":"2024-11-16T16:09:43.441126Z"}},"outputs":[{"name":"stdout","text":"Columns dropped: Index(['carbs-5:55', 'carbs-5:50', 'carbs-5:45', 'carbs-5:40', 'carbs-5:35',\n       'carbs-5:30', 'carbs-5:25', 'carbs-5:20', 'carbs-5:15', 'carbs-5:10',\n       ...\n       'activity-0:45', 'activity-0:40', 'activity-0:35', 'activity-0:30',\n       'activity-0:25', 'activity-0:20', 'activity-0:15', 'activity-0:10',\n       'activity-0:05', 'activity-0:00'],\n      dtype='object', length=288)\nUpdated df_train: (177024, 220)\nUpdated df_test: (3644, 219)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Drop the 'id' column from both datasets\ntrain_cleaned = train_cleaned.drop('id', axis=1)\ntest_cleaned = test_cleaned.drop('id', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.443509Z","iopub.execute_input":"2024-11-16T16:09:43.443883Z","iopub.status.idle":"2024-11-16T16:09:43.549985Z","shell.execute_reply.started":"2024-11-16T16:09:43.443840Z","shell.execute_reply":"2024-11-16T16:09:43.549119Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Convert time columns to hours, minutes, and seconds\ndef convert_time_columns(train_cleaned):\n    for col in train_cleaned.columns:\n        if pd.api.types.is_datetime64_any_dtype(train_cleaned[col]) or 'time' in col.lower():\n            train_cleaned[col] = pd.to_datetime(train_cleaned[col], errors='coerce')  # Convert to datetime\n            train_cleaned[col+'_hour'] = train_cleaned[col].dt.hour\n            train_cleaned[col+'_minute'] = train_cleaned[col].dt.minute\n#             train_cleaned[col+'_second'] = train_cleaned[col].dt.second\n            train_cleaned.drop(col, axis=1, inplace=True)  # Drop original time column after conversion\n# Apply time conversion to both train and test datasets\nconvert_time_columns(train_cleaned)\nconvert_time_columns(test_cleaned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.551299Z","iopub.execute_input":"2024-11-16T16:09:43.551685Z","iopub.status.idle":"2024-11-16T16:09:43.750646Z","shell.execute_reply.started":"2024-11-16T16:09:43.551648Z","shell.execute_reply":"2024-11-16T16:09:43.749574Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Handle 'p_num' in the test set: find unique values and replace them with numbers\nunique_pnums = test_cleaned['p_num'].unique()\npnum_mapping = {value: idx for idx, value in enumerate(unique_pnums)}\ntest_cleaned['p_num'] = test_cleaned['p_num'].map(pnum_mapping)\n\n# Also ensure the same mapping is applied to 'p_num' in the train set, if it exists\nif 'p_num' in train_cleaned.columns:\n    train_cleaned['p_num'] = train_cleaned['p_num'].map(pnum_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.752021Z","iopub.execute_input":"2024-11-16T16:09:43.752405Z","iopub.status.idle":"2024-11-16T16:09:43.779504Z","shell.execute_reply.started":"2024-11-16T16:09:43.752348Z","shell.execute_reply":"2024-11-16T16:09:43.778674Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(train_cleaned.shape)\nprint(test_cleaned.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.780765Z","iopub.execute_input":"2024-11-16T16:09:43.781116Z","iopub.status.idle":"2024-11-16T16:09:43.787262Z","shell.execute_reply.started":"2024-11-16T16:09:43.781081Z","shell.execute_reply":"2024-11-16T16:09:43.786400Z"}},"outputs":[{"name":"stdout","text":"(177024, 220)\n(3644, 219)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Use mean (you can also try mean or most_frequent based on your data)\nimputer = SimpleImputer(strategy='mean')\n\n# Fit on df_train and transform both df_train and df_test\ntrain_imputed = imputer.fit_transform(train_cleaned)\ntest_imputed = imputer.fit_transform(test_cleaned)\n\n# Convert the NumPy arrays back to DataFrames and retain the original column names\ntrain_cleaned = pd.DataFrame(train_imputed, columns=train_cleaned.columns)\ntest_cleaned = pd.DataFrame(test_imputed, columns=test_cleaned.columns)\n\n\ntrain_float_columns = train_cleaned.select_dtypes(include=['float64', 'float32']).columns.tolist()\ntest_float_columns = test_cleaned.select_dtypes(include=['float64', 'float32']).columns.tolist()\n\ntrain_cleaned[train_float_columns] = train_cleaned[train_float_columns].astype(float)\ntest_cleaned[test_float_columns] = test_cleaned[test_float_columns].astype(float)\n\nprint(train_cleaned.dtypes)\nprint(train_cleaned.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:43.788450Z","iopub.execute_input":"2024-11-16T16:09:43.788813Z","iopub.status.idle":"2024-11-16T16:09:45.283690Z","shell.execute_reply.started":"2024-11-16T16:09:43.788768Z","shell.execute_reply":"2024-11-16T16:09:45.282729Z"}},"outputs":[{"name":"stdout","text":"p_num          float64\nbg-5:55        float64\nbg-5:50        float64\nbg-5:45        float64\nbg-5:40        float64\n                ...   \ncals-0:05      float64\ncals-0:00      float64\nbg+1:00        float64\ntime_hour      float64\ntime_minute    float64\nLength: 220, dtype: object\nIndex(['p_num', 'bg-5:55', 'bg-5:50', 'bg-5:45', 'bg-5:40', 'bg-5:35',\n       'bg-5:30', 'bg-5:25', 'bg-5:20', 'bg-5:15',\n       ...\n       'cals-0:30', 'cals-0:25', 'cals-0:20', 'cals-0:15', 'cals-0:10',\n       'cals-0:05', 'cals-0:00', 'bg+1:00', 'time_hour', 'time_minute'],\n      dtype='object', length=220)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_cleaned.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:45.285110Z","iopub.execute_input":"2024-11-16T16:09:45.285564Z","iopub.status.idle":"2024-11-16T16:09:45.360047Z","shell.execute_reply.started":"2024-11-16T16:09:45.285518Z","shell.execute_reply":"2024-11-16T16:09:45.359117Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"p_num          0\nbg-5:55        0\nbg-5:50        0\nbg-5:45        0\nbg-5:40        0\n              ..\ncals-0:05      0\ncals-0:00      0\nbg+1:00        0\ntime_hour      0\ntime_minute    0\nLength: 220, dtype: int64"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"test_cleaned.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:45.361338Z","iopub.execute_input":"2024-11-16T16:09:45.361790Z","iopub.status.idle":"2024-11-16T16:09:45.382835Z","shell.execute_reply.started":"2024-11-16T16:09:45.361741Z","shell.execute_reply":"2024-11-16T16:09:45.381955Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"p_num          0\nbg-5:55        0\nbg-5:50        0\nbg-5:45        0\nbg-5:40        0\n              ..\ncals-0:10      0\ncals-0:05      0\ncals-0:00      0\ntime_hour      0\ntime_minute    0\nLength: 219, dtype: int64"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Prepare Features and Target Variable for Training Data\n\nx_train = train_cleaned.drop('bg+1:00', axis=1)\ny_train = train_cleaned['bg+1:00']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:45.384052Z","iopub.execute_input":"2024-11-16T16:09:45.384731Z","iopub.status.idle":"2024-11-16T16:09:45.508177Z","shell.execute_reply.started":"2024-11-16T16:09:45.384682Z","shell.execute_reply":"2024-11-16T16:09:45.507434Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"x_train_split, x_val, y_train_split, y_val = train_test_split(x_train, y_train, test_size = 0.2 , random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:45.509337Z","iopub.execute_input":"2024-11-16T16:09:45.509742Z","iopub.status.idle":"2024-11-16T16:09:46.084456Z","shell.execute_reply.started":"2024-11-16T16:09:45.509693Z","shell.execute_reply":"2024-11-16T16:09:46.083296Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom scipy import sparse\nimport numpy as np\nimport optuna\n\n# Reduce memory usage for dataframes\ndef reduce_memory_usage(df):\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type != object and col_type.name != 'category':\n            if col_type.kind in 'i':  # Integer\n                df[col] = pd.to_numeric(df[col], downcast='integer')\n            elif col_type.kind in 'f':  # Float\n                df[col] = pd.to_numeric(df[col], downcast='float')\n    return df\n\n# Sanitize feature names\ndef sanitize_feature_names(df):\n    return df.rename(columns=lambda x: x.replace(\"+\", \"_plus_\")\n                                    .replace(\":\", \"_colon_\")\n                                    .replace(\"-\", \"_dash_\")\n                                    .replace(\" \", \"_\"))\n\n# Apply to all datasets\nx_train_split = reduce_memory_usage(sanitize_feature_names(x_train_split))\nx_val = reduce_memory_usage(sanitize_feature_names(x_val))\nx_test = reduce_memory_usage(sanitize_feature_names(test_cleaned)).drop('bg_plus_1_00', axis=1, errors='ignore')\n\n# Ensure the target (y_train_split) matches x_train_split's index\ny_train_split = y_train_split.loc[x_train_split.index]\n\n# Feature engineering: Add polynomial interaction features\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nx_train_poly = sparse.csr_matrix(poly.fit_transform(x_train_split))\nx_val_poly = sparse.csr_matrix(poly.transform(x_val))\nx_test_poly = sparse.csr_matrix(poly.transform(x_test))\n\n# Power transform features for normalization\nscaler = StandardScaler()\npower_transformer = PowerTransformer()\n\nx_train_scaled = power_transformer.fit_transform(scaler.fit_transform(x_train_poly.toarray()))\nx_val_scaled = power_transformer.transform(scaler.transform(x_val_poly.toarray()))\nx_test_scaled = power_transformer.transform(scaler.transform(x_test_poly.toarray()))\n\n# Sample a subset of data for hyperparameter tuning\nx_train_sample = sparse.csr_matrix(x_train_scaled[:len(x_train_scaled) // 2])\ny_train_sample = y_train_split.iloc[:len(x_train_split) // 2]\n\n# Define the objective function for Optuna\ndef objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-4, 0.3),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 150),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 10.0),\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 10.0),\n        \"device\": \"gpu\",\n        \"gpu_id\": 0,\n    }\n\n    model = LGBMRegressor(**params, random_state=42)\n    selector = RFECV(estimator=model, step=10, cv=3, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n    selector.fit(x_train_sample.toarray(), y_train_sample)  # Use dense data only here\n\n    x_train_selected = x_train_sample[:, selector.support_]\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    rmse_scores = []\n\n    for train_idx, valid_idx in kf.split(x_train_selected, y_train_sample):\n        x_train_fold, x_valid_fold = x_train_selected[train_idx].toarray(), x_train_selected[valid_idx].toarray()\n        y_train_fold, y_valid_fold = y_train_sample.iloc[train_idx], y_train_sample.iloc[valid_idx]\n\n        model.fit(\n            x_train_fold, y_train_fold,\n            eval_set=[(x_valid_fold, y_valid_fold)],\n            eval_metric=\"rmse\",\n            callbacks=[early_stopping(stopping_rounds=10)]\n        )\n        y_pred_fold = model.predict(x_valid_fold)\n        fold_rmse = np.sqrt(mean_squared_error(y_valid_fold, y_pred_fold))\n        rmse_scores.append(fold_rmse)\n\n    return np.mean(rmse_scores)\n\n# Setup Optuna study\nstudy = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=50, n_jobs=-1)\n\n# Print best parameters\nprint(\"Best parameters:\", study.best_params)\nprint(\"Best RMSE:\", study.best_value)\n\n# Final model\nbest_params = study.best_params\nfinal_model = LGBMRegressor(**best_params, random_state=42)\n\n# Train on full dataset with selected features\nselector = RFECV(estimator=final_model, step=10, cv=3, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\nselector.fit(x_train_scaled, y_train_split)\nselected_features_mask = selector.support_\n\nx_train_selected = x_train_scaled[:, selected_features_mask]\nx_val_selected = x_val_scaled[:, selected_features_mask]\nx_test_selected = x_test_scaled[:, selected_features_mask]\n\nfinal_model.fit(x_train_selected, y_train_split)\n\n# Predict and evaluate\ny_val_pred = final_model.predict(x_val_selected)\nrmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\nprint(f\"Final RMSE on Validation Set: {rmse}\")\n\n# Predict on the test set\ntest_predictions = final_model.predict(x_test_selected)\nprint(\"Test Predictions:\", test_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T16:09:46.086316Z","iopub.execute_input":"2024-11-16T16:09:46.086841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualize Predictions\nplt.figure(figsize=(12, 6))\nplt.plot(y_val.values, label='Actual Glucose Levels')\nplt.plot(y_pred, label='Predicted Glucose Levels')\nplt.xlabel('Samples')\nplt.ylabel('Glucose Level')\nplt.title('Predicted vs Actual Glucose Levels')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save predictions to CSV\nsubmission = pd.DataFrame({'id': test['id'], 'bg+1:00': test_predictions})\nsubmission.to_csv(f'/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Model training, evaluation, and test predictions completed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}